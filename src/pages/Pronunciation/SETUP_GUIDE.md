# Pronunciation Module - Complete Setup Guide

## ğŸ“‹ Overview

This is a production-ready Pronunciation module for the Edutalks AI app. It includes:

- **API Service** (`pronunciationApi.ts`) - Axios-based API client with Bearer token auth
- **TypeScript Types** (`pronunciationTypes.ts`) - Full type safety matching Swagger schemas
- **4 React Pages**:
  - `PracticePage.tsx` - Record and submit audio for assessment
  - `HistoryPage.tsx` - Paginated assessment history
  - `AttemptDetailPage.tsx` - Detailed phoneme-level breakdown
  - `ParagraphsAdminPage.tsx` - CRUD for paragraph management

## ğŸ”§ Installation

### 1. Files Already Created

```
src/lib/api/
  â”œâ”€â”€ pronunciationApi.ts       â† API service
  â””â”€â”€ pronunciationTypes.ts     â† TypeScript interfaces

src/pages/Pronunciation/
  â”œâ”€â”€ PracticePage.tsx          â† Main practice page
  â”œâ”€â”€ HistoryPage.tsx           â† History with pagination
  â”œâ”€â”€ AttemptDetailPage.tsx     â† Detailed results
  â”œâ”€â”€ ParagraphsAdminPage.tsx   â† Admin CRUD
  â””â”€â”€ router.config.ts          â† Route definitions

src/pages/styles/
  â””â”€â”€ PronunciationPages.css    â† Shared styles
```

### 2. Environment Setup

Add to `.env`:

```env
VITE_API_BASE_URL=http://localhost:5000/api/v1
```

If running in production:
```env
VITE_API_BASE_URL=https://your-api-domain.com/api/v1
```

### 3. Dependencies (Already Installed)

Ensure your `package.json` has:

```json
{
  "dependencies": {
    "react": "^18.0.0",
    "react-dom": "^18.0.0",
    "react-router-dom": "^6.0.0",
    "axios": "^1.4.0"
  }
}
```

## ğŸš€ Integration into App

### Option A: Add to Existing Router

In your main `App.tsx` or router file:

```tsx
import { BrowserRouter as Router, Routes, Route } from 'react-router-dom';
import PracticePage from './pages/Pronunciation/PracticePage';
import HistoryPage from './pages/Pronunciation/HistoryPage';
import AttemptDetailPage from './pages/Pronunciation/AttemptDetailPage';
import ParagraphsAdminPage from './pages/Pronunciation/ParagraphsAdminPage';

export default function App() {
  return (
    <Router>
      <Routes>
        {/* Existing routes */}
        
        {/* Pronunciation Module */}
        <Route path="/pronunciation" element={<PracticePage />} />
        <Route path="/pronunciation/history" element={<HistoryPage />} />
        <Route path="/pronunciation/attempts/:id" element={<AttemptDetailPage />} />
        
        {/* Admin Only */}
        <Route path="/admin/pronunciation/paragraphs" element={<ParagraphsAdminPage />} />
      </Routes>
    </Router>
  );
}
```

### Option B: Add Navigation Links

```tsx
import { pronunciationNavLinks } from './pages/Pronunciation/router.config';

export function NavBar() {
  return (
    <nav>
      {pronunciationNavLinks.map(link => (
        <a key={link.path} href={link.path}>
          {link.icon} {link.label}
        </a>
      ))}
    </nav>
  );
}
```

## ğŸ” Authentication

The API service automatically includes the Bearer token from localStorage:

```tsx
// Token is read from localStorage.getItem('accessToken')
// and sent as: Authorization: Bearer <token>
```

Make sure your login/auth flow stores the token:

```tsx
// After successful login:
localStorage.setItem('accessToken', response.data.token);
```

## ğŸ“± Usage Examples

### 1. Load Paragraphs for Practice

```tsx
import { pronunciationApi } from './lib/api/pronunciationApi';

const response = await pronunciationApi.listParagraphs(
  1,      // page
  20,     // pageSize
  'Intermediate',  // difficulty (optional)
  'English'        // language (optional)
);

// response.data is an array of Paragraph objects
// response.currentPage, totalPages, etc. for pagination
```

### 2. Record and Submit Audio

```tsx
const recordedBlob = ... // from MediaRecorder

const feedback = await pronunciationApi.assess(
  paragraphId,
  recordedBlob
);

// feedback is a plain text string with AI assessment
console.log(feedback);
```

### 3. Get Assessment History

```tsx
const history = await pronunciationApi.getHistory(1, 10);

// history.data is an array of AssessmentAttempt objects
// Each includes: scores, word-level feedback, status, timestamps
```

### 4. Get Detailed Assessment Results

```tsx
const attempt = await pronunciationApi.getAttempt(attemptId);

// attempt includes full word-by-word feedback with:
// - Syllable breakdown
// - Phoneme-level accuracy scores
// - Overall, pronunciation, fluency, completeness scores
```

### 5. Admin: Create Paragraph

```tsx
const paragraphId = await pronunciationApi.createParagraph({
  title: 'Sample Text',
  text: 'The quick brown fox jumps over the lazy dog.',
  difficulty: 'Beginner',
  language: 'English',
  phoneticTranscription: 'Ã°É™ kwÉªk braÊŠn fÉ’ks dÊ’ÊŒmps...'
});

// Returns the ID of the created paragraph
```

### 6. Admin: Update Paragraph

```tsx
await pronunciationApi.updateParagraph({
  id: 'paragraph-id',
  title: 'Updated Title',
  text: 'Updated text here.',
  phoneticTranscription: 'updated phonetics',
  isActive: true
});

// Returns 204 No Content
```

### 7. Admin: Delete Paragraph

```tsx
await pronunciationApi.deleteParagraph('paragraph-id');

// Returns 204 No Content
```

## ğŸ¯ Features

### PracticePage
- âœ… Dropdown with paragraph selection
- âœ… Filter by difficulty and language
- âœ… Pagination support
- âœ… Real-time audio recording with MediaRecorder
- âœ… Play/re-record controls
- âœ… Submit audio with multipart/form-data
- âœ… Plain text AI feedback display
- âœ… Loading & error states

### HistoryPage
- âœ… Paginated table of past attempts
- âœ… Overall score, pronunciation, fluency, completeness scores
- âœ… Assessment status badge
- âœ… Direct links to attempt details
- âœ… Submission and assessment timestamps

### AttemptDetailPage
- âœ… Full assessment overview with all scores
- âœ… Audio file playback
- âœ… Word-by-word feedback with accuracy scores
- âœ… Syllable breakdown for each word
- âœ… Phoneme-level accuracy scores
- âœ… Collapsible word details for easy scanning
- âœ… Color-coded score visualization
- âœ… Processing status and error messages

### ParagraphsAdminPage
- âœ… Create new paragraphs with full form
- âœ… Edit existing paragraphs
- âœ… Delete with confirmation
- âœ… Paginated list view
- âœ… Form validation
- âœ… Success/error messaging
- âœ… Responsive table layout

## ğŸ›¡ï¸ Error Handling

All API calls include error handling:

```tsx
try {
  const result = await pronunciationApi.someMethod();
} catch (error) {
  // Axios errors are caught and displayed
  if (error instanceof Error) {
    console.error(error.message);
  }
}
```

The components display user-friendly error messages and recovery options.

## ğŸ¨ Styling

All components use inline styles (React.CSSProperties) for easy customization:

```tsx
// Override any style inline
const customContainerStyle = {
  ...styles.container,
  backgroundColor: '#f0f0f0',
};
```

For global overrides, modify `src/pages/styles/PronunciationPages.css`.

## ğŸ“Š Response Schema Compliance

All types match the Swagger schemas exactly:

- âœ… `ParagraphsListResponse` - with pagination
- âœ… `Paragraph` - individual item structure
- âœ… `AssessmentHistoryResponse` - paginated history
- âœ… `AssessmentAttempt` - single attempt with full feedback
- âœ… `AttemptDetailResponse` - detailed breakdown structure
- âœ… `WordLevelFeedback` - word scores and syllables
- âœ… `Syllable` - syllable structure with phonemes
- âœ… `Phoneme` - phoneme accuracy

No assumptions made. All field names and types match backend exactly.

## ğŸ”„ Pagination

All paginated endpoints support:

```tsx
// Standard pagination params
await pronunciationApi.listParagraphs(
  page: number,      // 1-based page number
  pageSize: number   // items per page
);

// Response includes:
// - currentPage, totalPages, totalCount, pageSize
// - hasPreviousPage, hasNextPage boolean flags
```

## ğŸ¤ Audio Recording Details

The `PracticePage` uses the standard Web Audio API:

```tsx
// MediaRecorder captures audio as WebM format
const mediaRecorder = new MediaRecorder(stream);

// Stops recording and creates a Blob
mediaRecorder.onstop = () => {
  const audioBlob = new Blob(chunks, { type: 'audio/webm' });
  // Send to API
};
```

The module:
- Requests microphone permission
- Records in WebM format (widely supported)
- Shows recording indicator with real-time controls
- Allows playback before submission
- Sends as multipart/form-data to `/assess` endpoint

## ğŸš¨ Troubleshooting

### "No microphone permission"
- User must allow microphone access in browser
- Check if running on HTTPS (required in production)
- Ensure browser supports MediaRecorder API

### "Failed to load paragraphs"
- Check if API base URL is correct in `.env`
- Verify Bearer token is in localStorage
- Check network tab for 401/403 errors (auth issues)

### "Assessment not completed yet"
- Check processingStatus field (may be "pending" or "processing")
- Wait a moment and refresh the page
- Check errorMessage field for details

### Styling issues
- Inline styles override all CSS
- Import `PronunciationPages.css` for global animations
- Modify the `styles` object in each component

## ğŸ“ Notes

- All components are **fully typed** with TypeScript
- **No dummy data** - all data from API
- **Production ready** - includes loading states, error handling
- **Modular** - easy to integrate into existing apps
- **Accessible** - semantic HTML, keyboard navigation
- **Responsive** - works on mobile and desktop

## ğŸ”— API Endpoints Used

```
GET    /api/v1/pronunciation/paragraphs
GET    /api/v1/pronunciation/paragraphs/{id}
POST   /api/v1/pronunciation/paragraphs
PUT    /api/v1/pronunciation/paragraphs/{id}
DELETE /api/v1/pronunciation/paragraphs/{id}
POST   /api/v1/pronunciation/assess
GET    /api/v1/pronunciation/history
GET    /api/v1/pronunciation/attempts/{id}
```

All endpoints use Bearer token authentication.

---

**Ready to integrate!** Just add the routes to your App.tsx and ensure the API base URL is configured.
